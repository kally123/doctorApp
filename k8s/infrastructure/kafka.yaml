# Kafka and Zookeeper for event streaming
# In production, consider using managed services like AWS MSK or Confluent Cloud
apiVersion: apps/v1
kind: Deployment
metadata:
  name: zookeeper
  namespace: healthcare
  labels:
    app: zookeeper
spec:
  replicas: 1
  selector:
    matchLabels:
      app: zookeeper
  template:
    metadata:
      labels:
        app: zookeeper
    spec:
      containers:
        - name: zookeeper
          image: confluentinc/cp-zookeeper:7.5.0
          ports:
            - containerPort: 2181
              name: client
          env:
            - name: ZOOKEEPER_CLIENT_PORT
              value: "2181"
            - name: ZOOKEEPER_TICK_TIME
              value: "2000"
          resources:
            requests:
              cpu: "100m"
              memory: "256Mi"
            limits:
              cpu: "500m"
              memory: "512Mi"
          volumeMounts:
            - name: zk-data
              mountPath: /var/lib/zookeeper/data
            - name: zk-log
              mountPath: /var/lib/zookeeper/log
      volumes:
        - name: zk-data
          emptyDir: {}
        - name: zk-log
          emptyDir: {}
---
apiVersion: v1
kind: Service
metadata:
  name: zookeeper-service
  namespace: healthcare
spec:
  type: ClusterIP
  ports:
    - port: 2181
      targetPort: 2181
      name: client
  selector:
    app: zookeeper
---
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: kafka
  namespace: healthcare
  labels:
    app: kafka
spec:
  serviceName: kafka
  replicas: 1
  selector:
    matchLabels:
      app: kafka
  template:
    metadata:
      labels:
        app: kafka
    spec:
      containers:
        - name: kafka
          image: confluentinc/cp-kafka:7.5.0
          ports:
            - containerPort: 9092
              name: kafka
          env:
            - name: KAFKA_BROKER_ID
              value: "1"
            - name: KAFKA_ZOOKEEPER_CONNECT
              value: "zookeeper-service.healthcare.svc.cluster.local:2181"
            - name: KAFKA_LISTENERS
              value: "INTERNAL://:9092"
            - name: KAFKA_ADVERTISED_LISTENERS
              value: "INTERNAL://kafka-service.healthcare.svc.cluster.local:9092"
            - name: KAFKA_LISTENER_SECURITY_PROTOCOL_MAP
              value: "INTERNAL:PLAINTEXT"
            - name: KAFKA_INTER_BROKER_LISTENER_NAME
              value: "INTERNAL"
            - name: KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR
              value: "1"
            - name: KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR
              value: "1"
            - name: KAFKA_TRANSACTION_STATE_LOG_MIN_ISR
              value: "1"
            - name: KAFKA_AUTO_CREATE_TOPICS_ENABLE
              value: "true"
            - name: KAFKA_LOG_RETENTION_HOURS
              value: "168"
          resources:
            requests:
              cpu: "200m"
              memory: "512Mi"
            limits:
              cpu: "1"
              memory: "2Gi"
          volumeMounts:
            - name: kafka-data
              mountPath: /var/lib/kafka/data
          livenessProbe:
            exec:
              command:
                - sh
                - -c
                - kafka-broker-api-versions --bootstrap-server localhost:9092
            initialDelaySeconds: 60
            periodSeconds: 30
            timeoutSeconds: 10
          readinessProbe:
            exec:
              command:
                - sh
                - -c
                - kafka-broker-api-versions --bootstrap-server localhost:9092
            initialDelaySeconds: 30
            periodSeconds: 10
            timeoutSeconds: 5
  volumeClaimTemplates:
    - metadata:
        name: kafka-data
      spec:
        accessModes: ["ReadWriteOnce"]
        storageClassName: standard
        resources:
          requests:
            storage: 20Gi
---
apiVersion: v1
kind: Service
metadata:
  name: kafka-service
  namespace: healthcare
spec:
  type: ClusterIP
  ports:
    - port: 9092
      targetPort: 9092
      name: kafka
  selector:
    app: kafka
